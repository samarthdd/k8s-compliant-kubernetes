# This is a workflow to build AMI with ICAP server

name: icap-server
env:
  AWS_DEFAULT_REGION: eu-west-1
# Controls when the action will run. Triggers the workflow on push or pull request
# events but only for the master branch
on:
  workflow_dispatch:
    inputs:
      icap_branch:
        description: icap-infrastructe branch to be used
        default: k8-develop
        required: false
      extra_regions:
        description: Extra regions where AMI should be published. Pass multiple regions with comma separated.
        default: eu-west-1
        required: false
      create_sc:
        description: Create Service Cluster
        default:  false
        required: true
      create_ova:
        description: Create OVA
        default: "true"
        required: true
  # push:
  #   branches: [ cs-api ]
  #   paths-ignore:
  #     - 'icap-client-docker'
  #     - '.github/workflows/proxy-rebuild-ova.yaml'
  #     - 'README.md'
  #     - 'Compliant_Kubernetes_ICAP_Service_with_Service_Cluster_Proxy_REST_API.json'

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  build-ami:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:

    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v2
      with:
        submodules: true

    # - name: Update submodules
    #   run: |
    #     git submodule foreach git fetch
    #     git submodule foreach git pull origin main

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: eu-west-1

    - name: Update and upgrade apt
      run: |
        sudo apt -y update && sudo apt -y upgrade

    - name: Setup PWGEN
      run: |
        sudo apt -y install pwgen

    - name: Setup PIP
      run: |
        sudo apt -y install python3-pip
        pip3 --version
        sudo pip3 install setuptools-rust setuptools
        sudo -H pip install setuptools

    - name: Setup compliantkubernetes-apps requirements
      run: |
        cd compliantkubernetes-apps
        ansible-playbook -e 'ansible_python_interpreter=/usr/bin/python3' --ask-become-pass --connection local --inventory 127.0.0.1, get-requirements.yaml

    # build artifact
    - name: Setup Packer
      run: |
        cd vmware-scripts/packer
        curl -o packer.zip https://releases.hashicorp.com/packer/1.6.6/packer_1.6.6_linux_amd64.zip
        unzip -o packer.zip
        sudo mv packer /usr/local/bin

    - name: Setup temporary SSH key
      run: |
        cd vmware-scripts/packer
        ssh-keygen -P "" -t rsa -b 4096 -m pem -f temp_ssh_key
        aws ec2 import-key-pair --key-name "packer-glasswall-elastisys-pipeline" --public-key-material fileb://temp_ssh_key.pub
        mkdir -p ../../compliant-k8s-icap-server-pipeline/wc-config/ssh
        cp temp_ssh_key ../../compliant-k8s-icap-server-pipeline/wc-config/ssh/id_rsa
        mkdir -p ../../compliant-k8s-icap-server-pipeline/sc-config/ssh
        cp temp_ssh_key ../../compliant-k8s-icap-server-pipeline/sc-config/ssh/id_rsa

    - name: Generate PGP key
      run: |
        cd compliant-k8s-icap-server-pipeline
        export GNUPGHOME=$(mktemp -d)
        echo "GNUPGHOME=$GNUPGHOME" >> $GITHUB_ENV
        ./pgp-generator.sh

    - name: Generate CK8s secrets
      run: |
        cd compliant-k8s-icap-server-pipeline
        ./secrets-generator.sh
        cat secrets.yaml # FOR DEBUG, TO BE REMOVED

    - name: Encrypt CK8s secrets and ssh keys
      env:
        GNUPGHOME: ${{ env.GNUPGHOME }}
      run: |
        cd compliant-k8s-icap-server-pipeline
        sops -i -e secrets.yaml
        sops -i -e wc-config/ssh/id_rsa
        sops -i -e sc-config/ssh/id_rsa

    - name: Build Workload Cluster AMI
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_DEFAULT_REGION }}
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        DOCKER_EMAIL: ${{ secrets.DOCKER_EMAIL }}
        GNUPGHOME: ${{ env.GNUPGHOME }}
      run: |
        cd vmware-scripts/packer
        export SHA8=${GITHUB_SHA::8}
        mkdir -p ../../compliant-k8s-icap-server-pipeline/.state
        PACKER_LOG=1 PACKER_LOG_PATH=packer.log packer build -var-file=aws-vars-pipeline.json -var create_ova=${{ github.event.inputs.create_ova }} -var region=${{ env.AWS_DEFAULT_REGION }} aws-ami.json

    - name: Build Service Cluster AMI
      if: ${{ github.event.inputs.create_sc }}
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_DEFAULT_REGION }}
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        DOCKER_EMAIL: ${{ secrets.DOCKER_EMAIL }}
        GNUPGHOME: ${{ env.GNUPGHOME }}
      run: |
        cd vmware-scripts/packer
        export SHA8=${GITHUB_SHA::8}
        mkdir -p ../../compliant-k8s-icap-server-pipeline/.state
        PACKER_LOG=1 PACKER_LOG_PATH=packer.log packer build -var-file=aws-vars-pipeline-sc.json aws-ami-sc.json

    - name: Delete temporary SSH key
      if: always()
      run: |
        aws ec2 delete-key-pair --key-name "packer-glasswall-elastisys-pipeline"

  # deploy-ami:
  #   runs-on: ubuntu-latest
  #   needs: build-ami
  #   steps:
  #     - name: Get the current instance id
  #       id: get_id
  #       env:
  #         AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  #         AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         AWS_DEFAULT_REGION: ${{ env.AWS_DEFAULT_REGION }}
  #       run: |
  #         # instance_id="${{ steps.deploy.outputs.instance_id }}"
  #         instance_id=$(aws ec2 describe-instances --filters 'Name=tag:Name,Values=dev-icap-server' "Name=instance-state-name,Values=running" --output text --query 'Reservations[*].Instances[*].InstanceId')
  #         echo ::set-output name=instance_id::$instance_id

  #     - name: Deploy AMI to dev
  #       id: deploy
  #       env:
  #         AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  #         AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         AWS_DEFAULT_REGION: ${{ env.AWS_DEFAULT_REGION }}
  #       run: |
  #         ami_id=$(aws ec2 describe-images --filters "Name=name,Values=icap-server-${{ github.sha }}" --query 'Images[*].[ImageId]' --output text)
  #         result=$(aws ec2 run-instances --image-id $ami_id --count 1 --instance-type t2.large --key-name packer --security-group-ids sg-0120400d5eefb0b9e --tag-specifications 'ResourceType=instance, Tags=[{Key=Name,Value=dev-icap-server}, {Key=Team, Value=k8-proxy/icap-server}, {Key=Owner, Value=githubactionAMIpacker}, {Key=AMI_Name, Value=icap-server-${{ github.sha }}}]' --block-device-mappings 'DeviceName=/dev/sda1,Ebs={DeleteOnTermination=true,VolumeSize=20,VolumeType=gp2}')
  #         sleep 10m
  #         instance_id=$(echo $result | jq -r ".Instances[0].InstanceId")
  #         echo "$instance_id is created."
  #         instance_description=$(aws ec2 describe-instances --instance-ids $instance_id)
  #         instance_state=$(echo $instance_description | jq -r ".Reservations[0].Instances[0].State.Name")
  #         echo "Instance state is $instance_state"
  #         if [[ "$instance_state" != "running" ]];then
  #             echo "EC2 instance $instance_id created from AMI has failed to start in time, terminating the instance." 
  #             aws ec2 terminate-instances --instance-ids $instance_id
  #             exit -1
  #         fi
  #         instance_ip=$(echo $instance_description | jq -r ".Reservations[0].Instances[0].PublicIpAddress")
  #         echo "Connect to the ICAP server at: ${instance_ip}"
  #         echo ::set-output name=instance_ip::$instance_ip
  #         echo ::set-output name=instance_id::$instance_id
  #         echo ::set-output name=ami_id::$ami_id

  #     - name: Checkout submodules
  #       uses: actions/checkout@v2
  #       with:
  #         repository: k8-proxy/vmware-scripts
  #         path: vmware-scripts

  #     - name: Run tests on the VM
  #       id: test
  #       env:
  #         AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  #         AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         AWS_DEFAULT_REGION: ${{ env.AWS_DEFAULT_REGION }}
  #       run: |
  #         instance_id="${{ steps.deploy.outputs.instance_id }}"
  #         instance_ip="${{ steps.deploy.outputs.instance_ip }}"
  #         ami_id="${{ steps.deploy.outputs.ami_id }}"
  #         sudo apt-get -y install c-icap
  #         cd vmware-scripts/HealthCheck
  #         sed -i "/icmp/I,+1 d" config.yml
  #         sed -i "/httpstring/I,+2 d" config.yml
  #         sed -i "s/54.77.168.168/$instance_ip/g" config.yml
  #         chmod +x ./pyCheck.py
  #         ./pyCheck.py
  #         test_result=$?
  #         if [[ $test_result -ne 0 ]];then
  #           echo ::set-output name=test_result::$test_result
  #         else
  #           echo "Tests are successfully on the new instance, terminating old instance."
  #           aws ec2 create-tags --resources $ami_id --tags Key=Test_Result,Value=Success
  #           instance_id="${{ steps.get_id.outputs.instance_id }}"
  #           if [[ ! -z "$instance_id" ]]; then
  #             echo "$instance_id" | while IFS= read -r line ; do aws ec2 terminate-instances --instance-ids $line || true; done
  #           fi
  #         fi

  #     - name: Delete instance if tests fail
  #       if: ${{ failure() }}
  #       env:
  #         AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  #         AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         AWS_DEFAULT_REGION: ${{ env.AWS_DEFAULT_REGION }}
  #       run: |
  #         test_result="${{ steps.test.outputs.test_result }}"
  #         if [[ $test_result != "0" ]];then
  #           echo "Failed integration tests, terminating the newly deployed VM"
  #           instance_id="${{ steps.deploy.outputs.instance_id }}"
  #           ami_id="${{ steps.deploy.outputs.ami_id }}"
  #           aws ec2 terminate-instances --instance-ids $instance_id
  #           aws ec2 create-tags --resources $ami_id --tags Key=Test_Result,Value=Failed
  #         fi
  #         exit $test_result
